<head>
	<style>
		body{
			color: #333;
		}
		#container{
			min-width: 1000px;
			width: 1000px;
/*			overflow: auto;
*/			margin: 50px auto;padding: 30px;
			/*zoom: 1;*/
/*			border: 1px solid #ccc;background: #fc9;color: #fff;
*/		}
		#left{
			float: left;
			width: 400px;
			height: 230px;
			margin-left: 0px;
		}
		#right{
			float: left;
			width: auto;
			margin-left: 50px;
		}
		#name{
			font-size: 22.0pt;
		    mso-bidi-font-size: 24.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		        font-weight: bold;
		}
		#info{
		    font-size: 16.0pt;
		    mso-bidi-font-size: 17.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    margin-top: 30px;
		    margin-left: 5px;
		    margin-bottom: 10px;
		    
		}
		.clear{clear:both; height: 0; line-height: 0; font-size: 0}
		.Bio{
			font-size:16.0pt;
			mso-bidi-font-size:17.0pt;
			line-height:150%;
			font-family:Times;
			mso-bidi-font-family:Lato-Regular;
			text-align: justify;
		}
		span.SpellE {
		    mso-style-name: "";
		    mso-spl-e: yes;
		}
		span.Title{
			    font-size: 22.0pt;
			    mso-bidi-font-size: 17.0pt;
			    font-family: Times;
			    mso-bidi-font-family: Lato-Regular;
			    font: bold;
			    margin-top: 10px;
		}
		div.section{
			padding-top: 30px;
		}
		
		div.sub-left{
			float: left;
			width: 250px;
						
		}
		div.sub-left img{
			vertical-align: middle;
			horizontal-align: middle;
			margin-top: 10px;
		}
		
		div.sub-left span{
			height: 100%;
			display: inline-block;
			vertical-align: top;
						
		}
		div.sub-right{
			float: left;
			width: 700px;			
		}
		.paper{
			overflow: auto;
			zoom:1;
			padding-bottom: 0px;
			min-height: 150px;

		}
		.paperTitle{
			font-size:14.0pt;
			mso-bidi-font-size:18.0pt;
			font-family:Times;
			mso-bidi-font-family:Times;
			margin-top: 10px;
			margin-bottom: 10px;
			font-weight: bold;
		}
		.paperName,.paperPub{
		    font-size: 12.0pt;
		    mso-bidi-font-size: 13.0pt;		    
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    line-height:150%;
		}
		.link{
		    font-size: 12.0pt;
		    mso-bidi-font-size: 13.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    margin-top: 10px;
		    margin-bottom: 0px;
		}
		.special{
		    margin-top: 0in;
		    margin-bottom: 0in;
		    margin-left: -.9pt;
		    margin-bottom: .0001pt;
		    text-indent: .9pt;
		    mso-pagination: none;
		    tab-stops: 13.75in;
		    mso-layout-grid-align: none;
		    text-autospace: none;
		}
		.long div.sub-left, .long div.sub-right{
			height: 300px;
			width: 950px;

		}
		.short div.sub-left, .short div.sub-right{
			height:160px;

		}
		div.sub-left,div.sub-right{
			height:200px;

		}
	</style>
</head>



<h3>
	<a name='publications'></a><strong>Main Publications</strong>
</h3>
		

		<br />
		<div class="paper short">
			<div class="sub-left">
				<span></span>
				<img src="assets/images/diffusion4d.jpg" width="240" height="130">
			</div>
			<div class="sub-right">
			<div class="media">
			<div class="media-body">
				<p class="media-heading">
				<strong>Diffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models</strong><br />
				Hanwen Liang&#42;, <strong>Yuyang Yin&#42;</strong>, Dejia Xu, Hanxue Liang, Zhangyang Wang, Konstantinos N. Plataniotis, Yao Zhao, Yunchao Wei
					<br />
<!-- 					Arxiv 2024.05<br /> -->
					Topic: 4D Generation<br />
					Advances in Neural Information Processing Systems (<strong>NeurIPS 2024</strong>)<br />
					
				<!-- ACM Multimedia (<strong>MM 2023</strong>)<br /> -->
				<a href="https://vita-group.github.io/Diffusion4D/">[Project]</a>
				<a href="https://arxiv.org/abs/2405.16645">[Paper]</a>
				<a href="https://github.com/VITA-Group/Diffusion4D">[Github]</a>
				</p>
			</div>
			</div>	
			</div>
		</div>

		<br />



		<div class="paper short">
			<div class="sub-left">
				<span></span>
				<img src="assets/images/4dgen.png" width="240" height="130">
			</div>
			<div class="sub-right">
			<div class="media">
			  <div class="media-body">
				<p class="media-heading">
				  <strong>4DGen: Grounded 4D Content Generation with Spatial-temporal Consistency</strong><br />
				   <strong>Yuyang Yin&#42;</strong>, Dejia Xu&#42;, Zhangyang Wang, Yao Zhao, Yunchao Wei<br />
				   Topic: 4D Generation<br />
					Arxiv 2023.12<br />
				   <!-- ACM Multimedia (<strong>MM 2023</strong>)<br /> -->
				   <a href="https://vita-group.github.io/4DGen/">[Project]</a>
				   <a href="https://arxiv.org/abs/2312.17225">[Paper]</a>
				   <a href="https://github.com/VITA-Group/4DGen">[Github]</a>
				</p>
			  </div>
			</div>	
			</div>
		</div>


		<div class="paper short">
			<div class="sub-left">
				<span></span>
				<img src="assets/images/cle.png" width="240" height="130">
			</div>
			<div class="sub-right">
			<div class="media">
			  <div class="media-body">
				<p class="media-heading">
				  <strong>CLE Diffusion: Controllable Light Enhancement Diffusion Model</strong><br />
				   <strong>Yuyang Yin</strong>, Dejia Xu, Chuangchuang Tan,Ping Liu, Yao Zhao, Yunchao Wei<br />
				   Topic: Image Enhancement<br />
				   ACM International Conference on Multimedia(<strong>MM 2023</strong>)<br />
				   <a href="https://yuyangyin.github.io/CLEDiffusion//">[Project]</a>
				   <a href="https://arxiv.org/pdf/2308.06725.pdf">[Paper]</a>
				   <a href="https://github.com/YuyangYin/CLEDiffusion">[Github]</a>
				</p>
			  </div>
			</div>	
			</div>
		</div>
<h3>
	<a name='publications'></a><strong>Other Publications</strong>
</h3>


			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/classdiffusion.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				<div class="media-body">
					<p class="media-heading">
					<strong>ClassDiffusion: More Aligned Personalization Tuning with Explicit Class Guidance</strong><br />
					Jiannan Huang, Jun Hao Liew, Hanshu Yan, <strong>Yuyang Yin</strong>, Yao Zhao, Humphrey Shi, Yunchao Wei
						<br />
	<!-- 					Arxiv 2024.05<br /> -->
						Topic: Image Generation<br />
						International Conference on Learning Representations (<strong>ICLR 2025</strong>)<br />
						
					<!-- ACM Multimedia (<strong>MM 2023</strong>)<br /> -->
					<a href="https://classdiffusion.github.io/">[Project]</a>
					<a href="https://arxiv.org/pdf/2405.17532">[Paper]</a>
					<a href="https://github.com/Rbrq03/ClassDiffusion">[Github]</a>
					</p>
				</div>
				</div>	
				</div>
			</div>


			<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/clipgs.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				<div class="media-body">
					<p class="media-heading">
					<strong>CLIP-GS: Unifying Vision-Language Representation with 3D Gaussian Splatting</strong><br />
					Siyu Jiao, Haoye Dong, <strong>Yuyang Yin</strong>, Zequn Jie, Yinlong Qian, Yao Zhao, Humphrey Shi, Yunchao Wei
						<br />
						Topic: 3D Understanding<br />
						Arxiv 2024.12<br />
						<!-- International Conference on Learning Representations (<strong>ICLR 2025</strong>)<br /> -->
						
					<!-- ACM Multimedia (<strong>MM 2023</strong>)<br /> -->
					<a href="https://arxiv.org/pdf/2412.19142">[Paper]</a>

					</p>
				</div>
				</div>	
				</div>
			</div>